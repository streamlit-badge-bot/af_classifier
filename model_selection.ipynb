{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single label Classifier - AF Detection\n",
    "\n",
    "Using the dataset provided by the 2020 Physionet Challenge we've developed an Atrial Fibrilation Detector trained to identify AF diagnosed patiences from a dataset containing patiances with different pathologies like: PAC, RBBB, I-AVB, PVC, LBBB, STD, STE and healthy individuals.\n",
    "\n",
    "Although data from 12-lead ECG was provided, for this first analysis we've only used the lead 2 data and we've processed the signals in order to create a dataframe consisting of features we believe will help us classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from xverse.transformer import WOE\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import display\n",
    "\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, fbeta_score, make_scorer, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can choose which lead data to load\n",
    "\n",
    "### Lead 2 data seems to give better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 'HRV-lead2'\n",
    "df_raw = pd.read_feather('datasets/phys-raw-lead2-HRV-corrected')\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(df_raw['label'])\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_raw = df_raw.loc[df_raw['age'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Redundant Features\n",
    "\n",
    "By calculating a Dendrogram we look for features that may be providing the same information so we can remove them and end up with a cleaner model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = np.round(scipy.stats.spearmanr(df_raw.drop('label',axis=1)).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "dendrogram = hc.dendrogram(z, labels=df_raw.drop('label',axis=1).columns, orientation='left', leaf_font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the variance can be obtained from the std, and viceversa it's no surprise they seem to provide the same information. Let's try and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['HRV_SDSD']\n",
    "df_raw = df_raw.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(df_raw.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming everything else as \"Non-AF\" in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.loc[df_raw.label != 'AF', 'label'] = 'Non-AF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(data=df_raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be an outlier so we'll remove that one from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw = df_raw.drop(df_raw.loc[df_raw.HRV_TINN > 12000,'HRV_TINN'].index)\n",
    "#df_raw = df_raw.drop(df_raw.loc[df_raw.mean_P_Peaks > 1000,'mean_P_Peaks'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "cols = df_raw.columns\n",
    "cols = cols.drop('label')\n",
    "for col in cols:\n",
    "    df = df[df[col] < df[col].quantile(.99)]\n",
    "    \n",
    "df_raw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(data=df_raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(30,10))\n",
    "#%time sns.pairplot(data=df_raw.sample(frac=0.1, random_state=42), hue='label', palette='Set2', height=1.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_feather('datasets/phys-raw-lead2-HRV-eda')\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(df_raw['label'])\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split between Train and Validation Datasets\n",
    "\n",
    "### Training Set (80%) - Validation (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_raw['label']\n",
    "X = df_raw.drop('label', axis=1)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the evaluation metrics we are actually interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'model':[], 'f1':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We process our datasets and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=4)\n",
    "\n",
    "%time lr.fit(X_train, y_train)\n",
    "\n",
    "f1_score(y_eval, lr.predict(X_eval), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Logistic Regression',\n",
    "                  'f1': f1_score(y_eval, lr.predict(X_eval), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "\n",
    "%time rf.fit(X_train, y_train)\n",
    "\n",
    "f1_score(y_eval, rf.predict(X_eval), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Random Forest',\n",
    "                  'f1': f1_score(y_eval, rf.predict(X_eval), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "%time svc.fit(X_train, y_train)\n",
    "\n",
    "f1_score(y_eval, svc.predict(X_eval), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'SVC',\n",
    "                  'f1': f1_score(y_eval, svc.predict(X_eval), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=4)\n",
    "\n",
    "%time knn.fit(X_train, y_train)\n",
    "\n",
    "f1_score(y_eval, knn.predict(X_eval), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'KNN',\n",
    "                  'f1': f1_score(y_eval, knn.predict(X_eval), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = StandardScaler()\n",
    "xtrain_scal = scal.fit_transform(X_train)\n",
    "xeval_scal = scal.transform(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=4)\n",
    "\n",
    "%time lr.fit(xtrain_scal, y_train)\n",
    "\n",
    "f1_score(y_eval, lr.predict(xeval_scal), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Logistic Regression Scal',\n",
    "                  'f1': f1_score(y_eval, lr.predict(xeval_scal), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "\n",
    "%time rf.fit(xtrain_scal, y_train)\n",
    "\n",
    "f1_score(y_eval, rf.predict(xeval_scal), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Random Forest Scal',\n",
    "                  'f1': f1_score(y_eval, rf.predict(xeval_scal), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "%time svc.fit(xtrain_scal, y_train)\n",
    "\n",
    "f1_score(y_eval, svc.predict(xeval_scal), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'SVC Scal',\n",
    "                  'f1': f1_score(y_eval, svc.predict(xeval_scal), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "%time knn.fit(xtrain_scal, y_train)\n",
    "\n",
    "f1_score(y_eval, knn.predict(xeval_scal), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'KNN Scal',\n",
    "                  'f1': f1_score(y_eval, knn.predict(xeval_scal), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check and see if there's a polynomical relation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpol_train = X_train.drop('age', axis=1)\n",
    "xpol_eval = X_eval.drop('age', axis=1)\n",
    "\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "xtrain_poly = poly.fit_transform(xpol_train)\n",
    "xeval_poly = poly.transform(xpol_eval)\n",
    "\n",
    "xtrain_poly = np.c_[xtrain_poly, X_train.age]\n",
    "xeval_poly = np.c_[xeval_poly, X_eval.age]\n",
    "\n",
    "scal = StandardScaler()\n",
    "xtrain_poly = scal.fit_transform(xtrain_poly)\n",
    "xeval_poly = scal.transform(xeval_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=4)\n",
    "\n",
    "%time lr.fit(xtrain_poly, y_train)\n",
    "\n",
    "f1_score(y_eval, lr.predict(xeval_poly), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Logistic Regression Poly',\n",
    "                  'f1': f1_score(y_eval, lr.predict(xeval_poly), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "\n",
    "%time rf.fit(xtrain_poly, y_train)\n",
    "\n",
    "f1_score(y_eval, rf.predict(xeval_poly), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Random Forest Poly',\n",
    "                  'f1': f1_score(y_eval, rf.predict(xeval_poly), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "%time svc.fit(xtrain_poly, y_train)\n",
    "\n",
    "f1_score(y_eval, svc.predict(xeval_poly), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'SVC Poly',\n",
    "                  'f1': f1_score(y_eval, svc.predict(xeval_poly), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=4)\n",
    "\n",
    "%time knn.fit(xtrain_poly, y_train)\n",
    "\n",
    "f1_score(y_eval, knn.predict(xeval_poly), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'KNN Poly',\n",
    "                  'f1': f1_score(y_eval, knn.predict(xeval_poly), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We take a look at Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = X_train.shape[1]\n",
    "\n",
    "pca = PCA(n_components = n_comps)\n",
    "\n",
    "train_pca = pca.fit_transform(xtrain_scal)\n",
    "\n",
    "eval_pca = pca.transform(xeval_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpca = pd.DataFrame(train_pca)\n",
    "\n",
    "sns.set_context(\"talk\", font_scale=0.7)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.scatter(xpca.loc[(y_train == 'AF').ravel(),0],xpca.loc[(y_train == 'AF').ravel(),1], alpha = 0.3, label = 'AF')\n",
    "plt.scatter(xpca.loc[(y_train == 'Non-AF').ravel(),0],xpca.loc[(y_train == 'Non-AF').ravel(),1], alpha = 0.3, label = 'Non-AF')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Principal Component Analysis before feature selection')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=4)\n",
    "\n",
    "%time lr.fit(train_pca, y_train)\n",
    "\n",
    "f1_score(y_eval, lr.predict(eval_pca), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Logistic Regression PCA',\n",
    "                  'f1': f1_score(y_eval, lr.predict(eval_pca), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "\n",
    "%time rf.fit(train_pca, y_train)\n",
    "\n",
    "f1_score(y_eval, rf.predict(eval_pca), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'Random Forest PCA',\n",
    "                  'f1': f1_score(y_eval, rf.predict(eval_pca), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "%time svc.fit(train_pca, y_train)\n",
    "\n",
    "f1_score(y_eval, svc.predict(eval_pca), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'SVC PCA',\n",
    "                  'f1': f1_score(y_eval, svc.predict(eval_pca), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=4)\n",
    "\n",
    "%time knn.fit(train_pca, y_train)\n",
    "\n",
    "f1_score(y_eval, knn.predict(eval_pca), pos_label='AF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.append({'model':'KNN PCA',\n",
    "                  'f1': f1_score(y_eval, knn.predict(eval_pca), pos_label='AF')}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rf.predict(eval_pca)\n",
    "\n",
    "cm = confusion_matrix(y_eval, ypred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = ['AF', 'Control'], columns = ['AF', 'Control'])\n",
    "plt.figure(figsize = (16,10))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('Classification Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence based on Tree Variance\n",
    "\n",
    "We take a look at the standard deviation among trees to see how confident we are about each classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([t.predict(eval_pca) for t in rf.estimators_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the statistical Bootstrap Method\n",
    "\n",
    "The bootstrap method is a popular non-parametric method, which does not require any distributional assumptions. Efron and Tibshirani provide a detailed review of the bootstrap method. The following is an algorithmic approach of obtaining a (1−α)100% percentile bootstrap conﬁdence interval for the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "n_iterations = 300\n",
    "n_size = int(len(preds) * 0.60)\n",
    "\n",
    "Lowers = []\n",
    "Uppers = []\n",
    "\n",
    "for i in range(len(preds[0])):\n",
    "    \n",
    "    means = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        rs = resample(preds[:, i], n_samples=n_size, replace=True)\n",
    "        means.append(np.mean(rs))\n",
    "    \n",
    "    alpha = 0.99\n",
    "    p = ((1.0 - alpha) / 2.0) * 100\n",
    "    lower = max(0.0, np.percentile(means, p))\n",
    "    Lowers.append(lower)\n",
    "    \n",
    "    p = (alpha + ((1.0 - alpha) / 2.0)) * 100\n",
    "    upper = min(1.0, np.percentile(means, p))\n",
    "    Uppers.append(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = pd.Categorical(y_eval)\n",
    "y = y_eval.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(eval_pca)\n",
    "\n",
    "X['actuals'] = y\n",
    "X['preds'] = np.mean(preds, axis=0)\n",
    "X['std'] = (np.std(preds, axis=0))\n",
    "X['upper'] = Uppers - np.mean(preds, axis=0)\n",
    "X['lower'] = np.mean(preds, axis=0) - Lowers\n",
    "X['var'] = (np.var(preds, axis=0))\n",
    "flds = ['actuals', 'preds', 'std', 'var', 'upper', 'lower']\n",
    "X.loc[:5,flds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and intervals for the first 50 samples of the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Control',\n",
    "    y=X['preds'][:50],\n",
    "    error_y=dict(\n",
    "            type='data',\n",
    "            symmetric=False,\n",
    "            array=X['upper'][:50],\n",
    "            arrayminus=X['lower'][:50])))\n",
    "\n",
    "fig.update_layout(shapes=[\n",
    "    dict(type= 'line', yref='y', y0= 0.5, y1= 0.5, xref= 'x', x0= -1, x1= 50)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We analyze those the model seems to be sure about it's classification\n",
    "\n",
    "Let's keep those where the prediction minus the lower limit error is above 0.9 and those where the prediction plus the upper limit error is below 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = X.loc[(X['preds'] - X['lower'] >= 0.7) | (X['preds'] + X['upper'] <= 0.3), flds]\n",
    "a = np.array(aux.preds > 0.5)\n",
    "\n",
    "aux['prediction'] = 0\n",
    "\n",
    "aux.loc[aux.preds > 0.5, 'prediction'] = 1\n",
    "\n",
    "f1_score(aux.actuals, aux.prediction, pos_label=0), len(aux), len(X), len(aux)/len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems we can predict 87% of this set with a 98% chance of being correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
